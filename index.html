<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="UTDesign: A Unified Framework for Stylized Text Editing and Generation in Graphic Design Images.">
  <meta name="keywords" content="stylized text editing, automatic graphic design, aigc, diffusion models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>UTDesign | Home</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script type="text/javascript"
    src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>

<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://art-msra.github.io/">
            ART
          </a>
          <a class="navbar-item" href="https://udifftext.github.io/">
            UDiffText
          </a>
        </div>
      </div>
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">UTDesign: A Unified Framework for Stylized Text Editing and Generation in Graphic Design Images</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/ZYM-PKU">Yiming Zhao</a><sup>1</sup>,</span>
            <span class="author-block">
              Yuanpeng Gao<sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/LoYuXr">Yuxuan Luo</a><sup>1</sup>,</span>
            <span class="author-block">
              Jiwei Duan<sup>2</sup>,</span>
            <span class="author-block">
              Shisong Lin<sup>2</sup>,</span> <br>
            <span class="author-block">
              Longfei Xiong<sup>2</sup>,</span>
            <span class="author-block">
              <a href="">Zhouhui Lian</a><sup>1â€ </sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <sup>1</sup><span class="author-block">Wangxuan Institute of Computer Technology, Peking University, </span>
            <sup>2</sup><span class="author-block">Kingsoft Office</span>
            <!-- <br> <FONT color=#8B0000><b>Accepted to CVPR 2025</b></FONT> -->
          </div>
          <div class="is-size-6 publication-authors">
            <!-- <sup>*</sup><span class="author-block">Equal contribution</span> -->
            <sup>â€ </sup><span class="author-block">Corresponding author</span>

          </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="./static/paper/TexGaussian.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!-- arXiv Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ZYM-PKU/UTDesign"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Model Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/UTDesign/UTDesign_v1.0"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      ðŸ¤—
                  </span>
                  <span>Model</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser.jpg"
               class="interpolation-image"
               alt="Interpolate start reference image"
               style="width: 100%; height: auto; display: block; margin: 0 auto;"> <br>
          <p class="imgae-description has-text-centered"> UTDesign supports editing arbitrary stylized text in design images (A) as well as generating complete design images (B). On the left side, we illustrate the pipeline for the two tasks, while the right side showcases the results of UTDesign across three different applications: (1) stylized text editing, (2) conditional stylized text generation, and (3) full design image generation.</p>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Video
      </h2>
     <video id="video" autoplay muted loop playsinline style="height: 80%;">
        <source src="./static/videos/short video.mp4"
                type="video/mp4">
      </video>
      <p class="video-description has-text-centered">Introducing UTDesign.</p>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          AI-assisted graphic design has emerged as a powerful tool for automating the creation and editing of design elements such as posters, banners and advertisements. While diffusion-based text-to-image models have demonstrated strong capabilities in visual content generation, their text rendering performance, particularly for small-scale typography and non-Latin scripts, remains limited. In this paper, we propose UTDesign, a unified framework for high-precision stylized text editing and conditional text generation in design images, supporting both English and Chinese scripts. Our framework introduces a novel DiT-based text style transfer model trained from scratch on a synthetic dataset, capable of generating transparent RGBA text foregrounds that preserve the style of reference glyphs. We further extend this model into a conditional text generation framework by training a multi-modal condition encoder on a curated dataset with detailed text annotations, enabling accurate, style-consistent text synthesis conditioned on background images, prompts, and layout specifications. Finally, we integrate our approach into an end-to-end text-to-design (T2D) pipeline by incorporating pre-trained text-to-image (T2I) models and an MLLM-based layout planner. Extensive experiments demonstrate that UTDesign achieves state-of-the-art performance among open-source methods in terms of stylistic consistency and text accuracy (with code to be released soon), and also exhibits unique advantages compared to proprietary commercial approaches.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="./static/videos/short video.mp4"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>

      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Animation. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>
        <!-- Interpolating. -->
          <div class="content has-text-justified">
          <img src="./static/images/method overview.png"
               class="interpolation-image"
               alt="Interpolate start reference image"
               style="width: 100%; height: auto; display: block; margin: 0 auto;"> <br>
          <p class="image-description has-text-centered">Overview of the proposed UTDesign. The first row illustrates the training stages of our model, including: Stage1 (1a): Train from scratch a DiT with content/style encoders to conduct style-preserved text editing; Stage2 (1b): Extract guidance condition from the design background and textual description using MLLM encoder and align the encoded features with the pre-trained style encoder; Stage3 (1c): Replace the style encoder with the MLLM encoder and form a conditional glyph generation model through post-training. The second raw illustrates the detailed structure of the proposed DiT (2a,2b,2c), and show the training process of our transparency glyph VAE (2d).</p>
<br><br>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Qualitative Results
      </h2>
      <img src="./static/images/show_edit.png"
            class="interpolation-image"
            alt="Interpolate start reference image"
            style="width: 100%; height: auto; display: block; margin: 0 auto;">
      <p class="image-description has-text-centered">Comparison of stylized text editing performance with strong baselines. The first column shows original images for selected editing scenarios, with
editing targets in the second column. The last three columns present results from three different methods.</p> <br>
      <img src="./static/images/show_full_gen.png"
        class="interpolation-image"
        alt="Interpolate start reference image"
        style="width: 100%; height: auto; display: block; margin: 0 auto;"> <br>
     <p class="image-description has-text-centered">System-level comparison with both open-source and close-source T2D models. We highlight the text rendering problems using red circles.</p> <br>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Quantitative Results
      </h2>
      <img src="./static/images/user study.png"
            class="interpolation-image"
            alt="Interpolate start reference image"
            style="width: 100%; height: auto; display: block; margin: 0 auto;">
      <p class="image-description has-text-centered">User study comparison with proprietary commercial systems.</p> <br>
      <img src="./static/images/result table.png"
        class="interpolation-image"
        alt="Interpolate start reference image"
        style="width: 100%; height: auto; display: block; margin: 0 auto;"> <br>
    <p class="image-description has-text-centered">System-level Comparison on the proposed UTDesign-Bench. We highlight the <span style="color: rgb(33,140,204);">best</span> and <span style="color: rgb(173,216,229);">second-best</span> scores in each column.</p> <br>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
            <div class="columns">
              <div class="column is-half">
              <p>
              This website is licensed under a <a rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
              </p>
              <p>
              This website borrows the template from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> and <a href="https://hypernerf.github.io/">HyperNeRF</a>.
              </p>
              </div>
              <div class="column is-one-quarter"></div> <!-- Empty column for spacing -->
              <div class="column is-one-quarter"> <!-- Column for the script -->
              <script type="text/javascript" id="mmvst_globe" src="//mapmyvisitors.com/globe.js?d=-n5qM5eNj6yn6azzUBbFlVBoc-4rzzCEboSHxf07Et8"></script>
              </div>
            </div>
        </div>
      </div>
    </div>

  </div>
</footer>

</body>
</html>
